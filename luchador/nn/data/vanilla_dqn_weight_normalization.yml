model_type: Sequential
layer_configs:
- scope: layer0/preprocessing
  layer:
    name: TrueDiv
    args:
      denom: 255
- scope: layer1/conv2D
  layer:
    name: Conv2D
    args:
      n_filters: 32
      filter_width: 8
      filter_height: 8
      strides: 4
      padding: valid
      initializers:
        bias: &initializer1
          name: Uniform
          args:
            # 1 / sqrt(8 * 8 * 32) = 0.022097
            maxval: 0.022
            minval: -0.022
        weight: *initializer1
- scope: layer1/ReLU
  layer:
    args: {{}}
    name: ReLU
- scope: layer2/conv2D
  layer:
    name: Conv2D
    args:
      n_filters: 64
      filter_width: 4
      filter_height: 4
      strides: 2
      padding: valid
      initializers:
        bias: &initializer2
          name: Uniform
          args:
            # 1 / sqrt(4 * 4 * 64) = 0.03125
            maxval: 0.031
            minval: -0.031
        weight: *initializer2
- scope: layer2/ReLU
  layer:
    name: ReLU
    args: {{}}
- scope: layer3/conv2D
  layer:
    name: Conv2D
    args:
      filter_width: 3
      filter_height: 3
      n_filters: 64
      strides: 1
      padding: valid
      initializers:
        bias: &initializer3
          name: Uniform
          args:
            # 1 / sqrt(3 * 3 * 64) = 0.04166
            maxval: 0.042
            minval: -0.042
        weight: *initializer3
- scope: layer3/ReLU
  layer:
    name: ReLU
    args: {{}}
- scope: layer4/flatten
  layer:
    name: Flatten
    args: {{}}
- scope: layer5/NormalizedDense
  layer:
    name: NormalizedDense
    args:
      n_nodes: 512
      with_bias: False
- scope: layer5/MeanOnlyBatchNormalization
  layer:
    name: BatchNormalization
    args:
      learn: True
      decay: 0.999
      mean_only: True
- scope: layer5/ReLU
  layer:
    name: ReLU
    args: {{}}
- scope: layer6/NormalizedDense
  layer:
    name: NormalizedDense
    args:
      n_nodes: {n_actions}
      initializers:
        bias: &initializer6
          name: Uniform
          args:
            # 1 / sqrt(512) = 0.04419
            maxval: 0.044
            minval: -0.044
        weight: *initializer6
