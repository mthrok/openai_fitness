{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3. Reinforcement Learning Problem\n",
    "In this tutorial we go through the example of computing action-value\n",
    "function and state-value function following the example given in Chapter 3\n",
    "of `Reinforcement Learning: An Introduction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "State value function and action value function for policy $\\pi$ are defined\n",
    "as follow\n",
    "\n",
    "\\begin{align*}\n",
    "v_{\\pi} (s)\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack G_t | S_t = s \\rbrack \\\\\n",
    "q_{\\pi}(s, a)\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack G_t | S_t = s, A_t = a \\rbrack \\\\\n",
    "\\text{where } & \\text{$G_t$ , the sum of the discounted rewards, is} \\\\\n",
    "G_t\n",
    "  &= R_{t+1} + R_{t+2} + R_{t+3} + \\dots + R_{T}\n",
    "\\end{align*}\n",
    "\n",
    "In case of Markov Decision Process, the following can be derived.\n",
    "\n",
    "\\begin{align*}\n",
    "v_{\\pi} (s)\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack G_t | S_t = s \\rbrack \\\\\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack \\sum_{k=0}^{\\infty}\n",
    "     \\gamma ^ {k} R_{t+k+1} | S_t = s \\rbrack \\\\\n",
    "q_{\\pi}(s, a)\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack G_t | S_t = s, A_t = a \\rbrack \\\\\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack \\sum_{k=0}^{\\infty}\n",
    "     \\gamma ^ {k} R_{t+k+1} | S_t = s, A_t = a \\rbrack\n",
    "\\end{align*}\n",
    "\n",
    "These interweived functions statisfy recursive relationships as follow\n",
    "\n",
    "\\begin{align*}\n",
    "v_{\\pi} (s)\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack G_t | S_t = s \\rbrack \\\\\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack\n",
    "     \\sum_{k=0}^{\\infty} \\gamma ^ k R_{t+k+1} | S_t = s \\rbrack \\\\\n",
    "  &= \\mathbb{E}_{\\pi} \\lbrack\n",
    "     R_{t+1} + \\gamma\n",
    "     \\sum_{k=0}^{\\infty} \\gamma ^ k R_{t+k+2} | S_t = s \\rbrack \\\\\n",
    "  &= \\sum_a \\pi(a|s) \\sum_{s'} p(s' |s, a) \\lbrack\n",
    "     r(s, a, s') + \\gamma \\mathbb{E}_{\\pi} \\lbrack\n",
    "         \\sum_{k=0}^{\\infty} \\gamma^{k} R_{t+k+2} | S_{t+1} = s'\n",
    "       \\rbrack\n",
    "     \\rbrack \\\\\n",
    "  &= \\sum_a \\pi(a|s) \\sum_{s'} p(s' |s, a) \\lbrack\n",
    "     r(s, a, s') + \\gamma v_{\\pi}(s')\n",
    "     \\rbrack\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute and visualize the state-value function through GridWorld\n",
    "example.\n",
    "For the detail of the definition, please refer to the Example 3.8\n",
    "from the book.\n",
    "- Agent moves in 5 x 5 grid cell\n",
    "- Agent takes action to move either north, east, west, or south.\n",
    "- Actions that would move the agent out of grid results in reward of -1\n",
    "and agent stays where it was before taking the action.\n",
    "- On success full action, agent moves to new position and receives\n",
    "0 reward.\n",
    "- In special state $A$ (0, 1), all action cause the agent to move to $A'$\n",
    "(4, 1) and reward of 10\n",
    "- Similarly in $B$ (0, 3), all action cause the agent to move to $B'$\n",
    "(2, 3) and reward of 5\n",
    "\n",
    "First, we define `GridWorld` environment as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import luchador.env\n",
    "import luchador.agent\n",
    "from luchador.episode_runner import EpisodeRunner\n",
    "\n",
    "\n",
    "def _transit(position, action):\n",
    "    \"\"\"Transition rule of GridWorld\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    position : NumPy NDArray\n",
    "        Coordinate of agent\n",
    "    action : int\n",
    "        0, 1, 2, or 3, meaning north, east, west or south respectively\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    NumPy NDArray\n",
    "        New coordinate\n",
    "    int\n",
    "        Reward\n",
    "    \"\"\"\n",
    "    reward = 0\n",
    "    new_position = position.copy()\n",
    "\n",
    "    if np.all(position == [0, 1]):\n",
    "        reward = 10\n",
    "        new_position[:] = [4, 1]\n",
    "        return new_position, reward\n",
    "    if np.all(position == [0, 3]):\n",
    "        reward = 5\n",
    "        new_position[:] = [2, 3]\n",
    "        return new_position, reward\n",
    "\n",
    "    if action == 0:  # North\n",
    "        move = [0, 1]\n",
    "    elif action == 1:  # East\n",
    "        move = [1, 0]\n",
    "    elif action == 2:  # West\n",
    "        move = [-1, 0]\n",
    "    elif action == 3:  # South\n",
    "        move = [0, -1]\n",
    "\n",
    "    new_position = new_position + move\n",
    "    if np.any(new_position < 0) or np.any(new_position > 4):\n",
    "        reward = -1\n",
    "        new_position[new_position < 0] = 0\n",
    "        new_position[new_position > 4] = 4\n",
    "    return new_position, reward\n",
    "\n",
    "\n",
    "class GridWorld(luchador.env.BaseEnvironment):\n",
    "    \"\"\"GridWorld Example from Sutton, Chapter3.\"\"\"\n",
    "    def __init__(self, seed=None):\n",
    "        self.position = None\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "\n",
    "    @property\n",
    "    def n_actions(self):\n",
    "        return 4\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset position randomly\"\"\"\n",
    "        self.position = self.rng.randint(5, size=2)\n",
    "        return luchador.env.Outcome(\n",
    "            reward=0, observation=self.position, terminal=False, state={})\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Move position based on action and transit rule\"\"\"\n",
    "        self.position, reward = _transit(self.position, action)\n",
    "        return luchador.env.Outcome(\n",
    "            reward=reward, observation=self.position, terminal=False, state={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create agent which\n",
    "- has equiprobable random policy\n",
    "- estimates of action-value function via Monte-Calro approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State value:\n",
      " [[ 3.30569427  8.78699243  4.42331714  5.31994367  1.48825901]\n",
      " [ 1.51852186  2.98933434  2.24694127  1.90463769  0.54457414]\n",
      " [ 0.04807821  0.7357133   0.67082204  0.3561573  -0.40502529]\n",
      " [-0.97596873 -0.43738304 -0.35655831 -0.5870724  -1.18447799]\n",
      " [-1.85956492 -1.34676746 -1.23060778 -1.42413428 -1.97638474]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAFkCAYAAABrUZ+8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJiZJUlFMTJKkovx/J5hSu3SK5/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10372fb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GridWorldAgent(luchador.agent.BaseAgent):\n",
    "    \"\"\"Agent walk on GridWorld with equiprobable random policy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        StepSize parameter for estimating action value function\n",
    "    gamma : float\n",
    "        Discount rate for computing state-value function\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.9, gamma=0.9, seed=None):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.position = None\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        self.action_values = np.zeros((5, 5, 4))\n",
    "\n",
    "    def init(self, _):\n",
    "        pass\n",
    "\n",
    "    def reset(self, observation):\n",
    "        self.position = observation\n",
    "\n",
    "    def observe(self, action, outcome):\n",
    "        pos0 = self.position\n",
    "        pos1 = outcome.observation\n",
    "\n",
    "        post_state_value = np.mean(self.action_values[pos1[0], pos1[1]])\n",
    "        target = outcome.reward + self.gamma * post_state_value\n",
    "        self.action_values[pos0[0], pos0[1], action] += self.alpha * (\n",
    "            target - self.action_values[pos0[0], pos0[1], action])\n",
    "        self.position = pos1\n",
    "\n",
    "    def act(self):\n",
    "        return np.random.choice(4)\n",
    "\n",
    "\n",
    "env = GridWorld(seed=0)\n",
    "agent = GridWorldAgent(seed=123)\n",
    "runner = EpisodeRunner(env, agent)\n",
    "\n",
    "runner.run_episode(max_steps=10000)\n",
    "\n",
    "state_value = np.mean(agent.action_values, axis=2)\n",
    "print('State value:\\n', state_value)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "img = ax.imshow(state_value, vmin=-2.0, vmax=9.0,\n",
    "                interpolation='nearest', origin='upper', animated=True)\n",
    "fig.colorbar(img)\n",
    "plt.show(block=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
