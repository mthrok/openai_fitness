name: AdamOptimizer
args:
  learning_rate: 0.001
  beta1: 0.9
  beta2: 0.999
  epsilon: 0.00000001
